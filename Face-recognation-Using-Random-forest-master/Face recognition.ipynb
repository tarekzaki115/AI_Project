{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# first way to load the dataset from sklearn data sete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "dataset = fetch_olivetti_faces()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discover and understand our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Keys of fetch_olivetti_faces: \\n{}\".format(dataset.keys())) #to see the keys of our dataset\n",
    "print(dataset.data.shape)\n",
    "print(len(dataset.data[1]))\n",
    "print(dataset.data[61])\n",
    "print(dataset['DESCR'][:1000] + \"\\n...\")\n",
    "print(\"Type of data: {}\".format(type(dataset['data']))+\"\\n\")\n",
    "print(\"First six columns of data:\\n{}\".format(dataset['data'][:6]))\n",
    "\n",
    "dataset.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports of  essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd  #to see the dir of our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second way to load the dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"olivetti_faces.npy\")  #https://www.kaggle.com/serkanpeldek/face-recognition-on-olivetti-dataset/data\n",
    "target=np.load(\"olivetti_faces_target.npy\")\n",
    "X= data\n",
    "y=target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show the details of dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} images in the dataset\".format(len(data)))\n",
    "print(\"There are {} unique targets in the dataset\".format(len(np.unique(target))))\n",
    "print(\"Size of each image is {}x{}\".format(data.shape[1],data.shape[2]))\n",
    "print(\"Pixel values were scaled to [0,1] interval. e.g:{}\".format(data[0][0,:4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show 8 random faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "idx_rand = np.random.randint(len(data), size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 8))\n",
    "for p, i in enumerate(idx_rand):\n",
    "    plt.subplot(2, 4, p + 1)\n",
    "    plt.imshow(data[i, :].reshape((64, 64)), cmap='gray')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unique target number:\",np.unique(target)) #our images labled from 0 :39\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show the 40 face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_40_distinct_people(images, unique_ids):\n",
    "    #Creating 4X10 subplots in  18x9 figure size\n",
    "    fig, axarr=plt.subplots(nrows=4, ncols=10, figsize=(18, 9))\n",
    "    #For easy iteration flattened 4X10 subplots matrix to 40 array\n",
    "    axarr=axarr.flatten()\n",
    "    \n",
    "    #iterating over user ids\n",
    "    for unique_id in unique_ids:\n",
    "        image_index=unique_id*10\n",
    "        axarr[unique_id].imshow(images[image_index], cmap='gray')\n",
    "        axarr[unique_id].set_xticks([])\n",
    "        axarr[unique_id].set_yticks([])\n",
    "        axarr[unique_id].set_title(\"face id:{}\".format(unique_id))\n",
    "    plt.suptitle(\"There are 40 distinct people in the dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_40_distinct_people(data, np.unique(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_10_faces_of_n_subject(images, subject_ids):\n",
    "    cols=10# each subject has 10 distinct face images\n",
    "    rows=(len(subject_ids)*10)/cols #\n",
    "    rows=int(rows)\n",
    "    \n",
    "    fig, axarr=plt.subplots(nrows=rows, ncols=cols, figsize=(18,9))\n",
    "    #axarr=axarr.flatten()\n",
    "    \n",
    "    for i, subject_id in enumerate(subject_ids):\n",
    "        for j in range(cols):\n",
    "            image_index=subject_id*10 + j\n",
    "            axarr[i,j].imshow(images[image_index], cmap=\"gray\")\n",
    "            axarr[i,j].set_xticks([])\n",
    "            axarr[i,j].set_yticks([])\n",
    "            axarr[i,j].set_title(\"face id:{}\".format(subject_id))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_10_faces_of_n_subject(images=data, subject_ids=[0,5, 6, 24, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We reshape images for machine learnig  model before send it to calssifiar \n",
    "X=data.reshape((data.shape[0],data.shape[1]*data.shape[2]))\n",
    "print(\"X shape:\",X.shape)\n",
    "X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #split our data\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=21,test_size=0.2\n",
    "    #this is the hyper paramter\n",
    ")\n",
    "print(\"X_train shape:\",X_train.shape)\n",
    "print(\"y_train shape:{}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100 , random_state=21)\n",
    "#create 100 descision tree and take the majority voting of them\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(X_test[2]) \n",
    "print(y_pred[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#to show the accuracy\n",
    "print(\"Accuracy:%\",metrics.accuracy_score(y_test, y_pred)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# another way to know the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_test)\n",
    "y_pred = clf.predict(X_test) \n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the single decision tree will give us low accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=21, max_depth=25)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # classification report of our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_pred, y_test)) #actual_pred\n",
    "#print(metrics.classification_report(y_test, clf.predict(X_test))) #actual_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='b', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "\n",
    "print(mat)\n",
    "#why he print the right way of the mat ? tell me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "plt.figure(1, figsize=(12,8))\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#mglearn.plots.plot_cross_validation()\n",
    "\n",
    "scores = cross_val_score(clf, X, y)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:9000/api\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  فيه فانكشن اسمها\n",
    "rescale\n",
    "from skimage.transform import rescale\n",
    "rescale(image , 1/4 , anti_aliasing = True , multichannal = true)\n",
    "resize  برضو\n",
    "resize(image , (width,hight) , antialaising = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
